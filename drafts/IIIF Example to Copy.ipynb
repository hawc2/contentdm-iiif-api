{"cells":[{"cell_type":"markdown","metadata":{"id":"WMFNIcdipS6y"},"source":["# Demo Notebook for the IIIF Workshop at Coding da Vinci Ost 2018 in Leipzig, Germany\n","\n","https://codingdavinci.de/events/ost/\n","\n","This notebook makes use of public IIIF data from the National Gallery of Art.\n","Leander Seige, seige@ub.uni-leipzig.de\n","\n","### Step 1: Import some libraries."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rgKde5FRpS62"},"outputs":[],"source":["%matplotlib inline\n","import numpy as np\n","import urllib.request\n","from matplotlib import pyplot as plt\n","import cv2\n","import json\n","from IPython.display import Image, display\n","from IPython.core.display import HTML \n","import ipywidgets as widgets\n","from random import randint"]},{"cell_type":"markdown","metadata":{"id":"dnOJLJRFpS63"},"source":["### Step 2: Read IIIF Image API endpoints from NGAs Highlights Manifest."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"LxWJs5K-pS64"},"outputs":[],"source":["url = \"https://media.nga.gov/public/manifests/nga_highlights.json\"\n","resp = urllib.request.urlopen(url)\n","data = resp.read().decode(\"utf-8\")\n","data = json.loads(data)\n","pid = 0\n","img_urls = {}\n","for c in data['sequences'][0]['canvases']:\n","    img_urls[pid]=c['images'][0]['resource']['service']['@id']\n","    print (img_urls[pid])\n","    pid = pid +1\n","    \n","print (\"Ready.\")"]},{"cell_type":"markdown","metadata":{"id":"n5Iln9kopS66"},"source":["### Step 3: Let's get us some generic progress bar."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6EYjPqcSpS66"},"outputs":[],"source":["progbar = widgets.IntProgress(\n","    value=0,\n","    min=0,\n","    max=pid,\n","    step=1,\n","    description='Progress:',\n","    bar_style='', # 'success', 'info', 'warning', 'danger' or ''\n","    orientation='horizontal'\n",")"]},{"cell_type":"markdown","metadata":{"id":"ECoa2IQEpS67"},"source":["### Step 4: Define a function to read a binary image from the web."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"km1bQb3qpS68"},"outputs":[],"source":["def url_to_image(url):\n","    resp = urllib.request.urlopen(url)\n","    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n","    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    return image"]},{"cell_type":"markdown","metadata":{"id":"FMcwRePOpS69"},"source":["### Step 5: Read all images with 4% of their actual size."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3_Cyb8rbpS69"},"outputs":[],"source":["display(progbar)\n","\n","img_smalls = {}\n","for pid in img_urls:\n","    progbar.value = pid\n","    turl = img_urls[pid]+\"/full/pct:4,/0/native.jpg\"\n","    img_smalls[pid] = url_to_image(turl)\n","    display(Image(url=turl, width=400, height=400))\n","    if pid == 1000:\n","        break"]},{"cell_type":"markdown","metadata":{"id":"_Fo18HXypS6-"},"source":["### Step 6: Get us a function to detect faces using the opencv lib."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PridZ2RXpS6_"},"outputs":[],"source":["def analyze_images(image):\n","    faceCascade = cv2.CascadeClassifier(\"haarcascades/haarcascade_frontalface_alt.xml\")\n","    faces = faceCascade.detectMultiScale(\n","        image,\n","        scaleFactor=1.1,\n","        minNeighbors=3,\n","        minSize=(20, 20),\n","        flags = cv2.CASCADE_SCALE_IMAGE\n","    )\n","    return faces"]},{"cell_type":"markdown","metadata":{"id":"KCCWCKcppS7A"},"source":["### Step 7: Find all faces in the images.\n","Save all coodinates multiplied by 25 as we retrieved the images scaled to 4%."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_vaQjqAPpS7A"},"outputs":[],"source":["display(progbar)\n","\n","faces_xy = {}\n","fid = 0\n","for pid in img_smalls:\n","    progbar.value=pid\n","    faces = analyze_images(img_smalls[pid])\n","    for (x, y, w, h) in faces:\n","        faces_xy[fid] = {}\n","        faces_xy[fid]['pid'] = pid\n","        faces_xy[fid]['x'] = x*25\n","        faces_xy[fid]['y'] = y*25\n","        faces_xy[fid]['w'] = w*25\n","        faces_xy[fid]['h'] = h*25\n","        fid = fid +1\n","        \n","print (\"Found {0} faces!\".format(len(faces_xy)))"]},{"cell_type":"markdown","metadata":{"id":"HREntww9pS7B"},"source":["### Step 8: Generate URLs to the facial regions for each recognized face."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"uWViyCI1pS7B"},"outputs":[],"source":["for fid in faces_xy:\n","    pid = faces_xy[fid]['pid']\n","    x = faces_xy[fid]['x']\n","    y = faces_xy[fid]['y']\n","    w = faces_xy[fid]['w']\n","    h = faces_xy[fid]['h']\n","    url = img_urls[pid]+\"/%d,%d,%d,%d/300,/0/native.jpg\"%(x,y,w,h)\n","    faces_xy[fid]['quick_url'] = url"]},{"cell_type":"markdown","metadata":{"id":"9_gJUtJTpS7C"},"source":["### Step 9: Display what we have done so far."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ElrRHRHzpS7C"},"outputs":[],"source":["for fid in faces_xy:\n","    print(faces_xy[fid]['quick_url'])\n","    display(Image(url=faces_xy[fid]['quick_url']))\n","    "]},{"cell_type":"markdown","metadata":{"id":"b1ma0M_cpS7D"},"source":["### Use Case 1: A IIIF Memory Game\n","\n","Write all face URLs to a Javascript file in order to feed them into a Memory game. This game actually uses IIIF Image API endpoints. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7lVSqTzEpS7D"},"outputs":[],"source":["file = open(\"game/urls.js\",\"w\") \n","file.write(\"var urls=[\") \n","for fid in faces_xy:\n","    if fid > 0:\n","        file.write(\",\")\n","    file.write('\"'+faces_xy[fid]['quick_url']+'\"')\n","file.write(\"];\")  \n","file.close() \n","\n","HTML('<a target=\"_blank\" href=\"game/game.html\">Game</a>')"]},{"cell_type":"markdown","metadata":{"id":"6XKpuHwfpS7D"},"source":["### Use Case 2: Random Avatar Generator.\n","\n","Choose randomly the upper 50% of a face, the middle 20% of another face and the lower 30% of a third face and combine it to a random patchwork portrait. Click on the image parts to flip the image horizontally."]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"l01jhrZJpS7D"},"outputs":[],"source":["efile = open(\"generator/eurls.js\",\"w\") \n","efile.write(\"var eurls=[\") \n","\n","nfile = open(\"generator/nurls.js\",\"w\") \n","nfile.write(\"var nurls=[\") \n","\n","mfile = open(\"generator/murls.js\",\"w\") \n","mfile.write(\"var murls=[\") \n","\n","for fid in faces_xy:\n","    if fid > 0:\n","        efile.write(\",\")\n","        nfile.write(\",\")\n","        mfile.write(\",\")\n","    u = img_urls[faces_xy[fid]['pid']]\n","    x = faces_xy[fid]['x']\n","    y = faces_xy[fid]['y']\n","    w = faces_xy[fid]['w']\n","    h = faces_xy[fid]['h']\n","    efile.write('\"'+u+\"/%d,%d,%d,%d/300,/0/native.jpg\"%(x,y,w,int(h*0.5))+'\"');\n","    nfile.write('\"'+u+\"/%d,%d,%d,%d/300,/0/native.jpg\"%(x,y+int(h*0.5),w,int(h*0.2))+'\"');\n","    mfile.write('\"'+u+\"/%d,%d,%d,%d/300,/0/native.jpg\"%(x,y+int(h*0.7),w,int(h*0.3))+'\"');\n","\n","efile.write(\"];\")  \n","efile.close() \n","\n","nfile.write(\"];\")  \n","nfile.close() \n","\n","mfile.write(\"];\")  \n","mfile.close() \n","\n","HTML('<a target=\"_blank\" href=\"generator/index.html\">Generator</a>')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3YfC8LSYpS7E"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ysX9OC_zpS7E"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"colab":{"name":"Copy of IIIF_CDVOST2018_NB1_OPENCV.ipynb","provenance":[{"file_id":"10Zr_X229xZ_jNCZGhb8K2E8DL0bYewfd","timestamp":1640638003434}]}},"nbformat":4,"nbformat_minor":0}